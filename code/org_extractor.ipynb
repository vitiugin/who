{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob('data/full_who_dataset*.csv')\n",
    "dataframes = [pd.read_csv(open(f, 'rb')) for f in filenames]\n",
    "data = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Unnamed: 0', 'level_0', 'index', ' '])\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract tweets from/about organisations from list of organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a11 = pd.read_csv('data/org/a11.tsv', delimiter='\\t')\n",
    "data_a12 = pd.read_csv('data/org/a12.tsv', delimiter='\\t')\n",
    "data_a14 = pd.read_csv('data/org/a14.tsv', delimiter='\\t')\n",
    "#data_cat = pd.read_csv('data/org/cat.tsv', delimiter='\\t')\n",
    "#data_brazil = pd.read_csv('data/org/brazil.tsv', delimiter='\\t')\n",
    "data_brazil = pd.read_csv('data/org/brazil_gov.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_extraction(dataframe):\n",
    "    for x in range(len(dataframe)):\n",
    "        org = []\n",
    "        org_mention = dataframe.loc[x]['account']\n",
    "        org_account = re.sub('@', '', org_mention)\n",
    "        org_local_name = dataframe.loc[x]['local_name']\n",
    "        org_en_name = dataframe.loc[x]['english_name']\n",
    "\n",
    "        for num, row in enumerate(data['text']):\n",
    "            if type(org_mention) == str:\n",
    "                if re.findall(org_mention, str(row)):\n",
    "                    org.append(data.loc[num]) # ['text'])\n",
    "            elif type(org_local_name) == str:\n",
    "                if re.findall(org_local_name, str(row)):\n",
    "                    org.append(data.loc[num]) #['text'])\n",
    "            elif type(org_en_name) == str:\n",
    "                if re.findall(org_en_name, str(row)):\n",
    "                    org.append(data.loc[num]) #['text'])\n",
    "        \n",
    "        for num, row in enumerate(data['from_user']):\n",
    "            if org_account == row:\n",
    "                org.append(data.loc[num]) #['text'])\n",
    "                \n",
    "        \n",
    "        org_data = pd.DataFrame(org)\n",
    "        print(len(org_data))\n",
    "        org_data.drop_duplicates(subset =\"id_str\", keep = False, inplace = True)\n",
    "        org_data.drop_duplicates(subset =\"text\", keep = False, inplace = True)\n",
    "        org_data.drop_duplicates(keep = False, inplace = True)\n",
    "        org_data = org_data.reset_index(drop=True)\n",
    "        org_data.to_csv('data/out/cat/cat_'+ org_account +'.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brazil_extraction(dataframe):\n",
    "    brazil_dataset = pd.DataFrame()\n",
    "    for x in range(len(dataframe)):\n",
    "        org = []\n",
    "        org_mention = dataframe.loc[x]['account']\n",
    "        org_account = re.sub('@', '', org_mention)\n",
    "        org_local_name = dataframe.loc[x]['local_name']\n",
    "        org_en_name = dataframe.loc[x]['english_name']\n",
    "\n",
    "        for num, row in enumerate(data['text']):\n",
    "            if type(org_mention) == str:\n",
    "                if re.findall(org_mention, str(row)):\n",
    "                    org.append(data.loc[num]) # ['text'])\n",
    "            elif type(org_local_name) == str:\n",
    "                if re.findall(org_local_name, str(row)):\n",
    "                    org.append(data.loc[num]) #['text'])\n",
    "            elif type(org_en_name) == str:\n",
    "                if re.findall(org_en_name, str(row)):\n",
    "                    org.append(data.loc[num]) #['text'])\n",
    "        \n",
    "        for num, row in enumerate(data['from_user']):\n",
    "            if org_account == row:\n",
    "                org.append(data.loc[num]) #['text'])\n",
    "                \n",
    "        \n",
    "        org_data = pd.DataFrame(org)\n",
    "        org_data.drop_duplicates(subset =\"id_str\", keep = False, inplace = True)\n",
    "        org_data.drop_duplicates(subset =\"text\", keep = False, inplace = True)\n",
    "        org_data.drop_duplicates(keep = False, inplace = True)\n",
    "        org_data = org_data.reset_index(drop=True)\n",
    "        print(len(org_data))\n",
    "        brazil_dataset = pd.concat([brazil_dataset, org_data])\n",
    "        \n",
    "        \n",
    "    brazil_dataset.to_csv('data/out/brazil_gov.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "179\n",
      "105\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#org_extraction(data_cat)\n",
    "brazil_extraction(data_brazil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing timeline graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_plot(data, g_step, name, filename):\n",
    "    graph = {}\n",
    "    for t in data:\n",
    "        if t not in graph:\n",
    "            graph[t] = 1\n",
    "        else:\n",
    "            graph[t] += 1\n",
    "    graph = pd.DataFrame(graph.items(), columns=['date', 'mentions'])\n",
    "    graph = graph.sort_values(by=['date'])\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.plot(graph['date'], graph['mentions'], '-', color='green')\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Number of mentions / tweets from organisation')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(np.arange(0, max(graph['mentions']), g_step))\n",
    "    plt.title(name, bbox={'facecolor': '0.8', 'pad': 5})\n",
    "    fig.savefig('data/graphs/' + filename + '.png')\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "\n",
    "def timeline(dataframe):\n",
    "    for x in range(len(dataframe)):\n",
    "        time = []\n",
    "        org_mention = dataframe.loc[x]['account']\n",
    "        org_account = re.sub('@', '', org_mention)\n",
    "        org_local_name = dataframe.loc[x]['local_name']\n",
    "        org_en_name = dataframe.loc[x]['english_name']\n",
    "\n",
    "        for num, row in enumerate(data['text']):\n",
    "            if type(org_mention) == str:\n",
    "                if re.findall(org_mention, str(row)):\n",
    "                    time.append(data.loc[num]['time'][:10])\n",
    "            elif type(org_local_name) == str:\n",
    "                if re.findall(org_local_name, str(row)):\n",
    "                    time.append(data.loc[num]['time'][:10])\n",
    "            elif type(org_en_name) == str:\n",
    "                if re.findall(org_en_name, str(row)):\n",
    "                    time.append(data.loc[num]['time'][:10])\n",
    "        for num, row in enumerate(data['from_user']):\n",
    "            if org_account == row:\n",
    "                time.append(data.loc[num]['time'][:10])\n",
    "        \n",
    "        if len(time) >= 100 and len(time) < 200 :\n",
    "            save_plot(time, 5, org_account, org_account)\n",
    "        elif len(time) >= 200 and len(time) < 500 :\n",
    "            save_plot(time, 10, org_account, org_account)\n",
    "        elif len(time) >= 500 and len(time) < 1000 :\n",
    "            save_plot(time, 30, org_account, org_account)\n",
    "        elif len(time) >= 1000 and len(time) < 10000 :\n",
    "            save_plot(time, 50, org_account, org_account)\n",
    "        elif len(time) > 10000 :\n",
    "            save_plot(time, 100, org_account, org_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeline(data_cat)\n",
    "timeline(data_brazil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find top-50 most frequent messages from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50 = {}\n",
    "\n",
    "for text in data['text']:\n",
    "    if text not in top50:\n",
    "        top50[text] = 1\n",
    "    else:\n",
    "        top50[text] += 1\n",
    "\n",
    "top50_freq = sorted(top50.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "who",
   "language": "python",
   "name": "who"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}